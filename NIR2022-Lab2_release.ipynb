{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIR 2022 - Lab 2: Introduction to PyTerrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Libraries for Indexing and Ranking\n",
    "\n",
    "There exist several software libraries that can help you develop a search engine.\n",
    "They usually provide highly optimized indexes, scoring algorithms (e.g. BM25) and other features such as text pre-processing.\n",
    "\n",
    "Popular libraries include:\n",
    "- [INDRI](https://www.lemurproject.org/indri/)\n",
    "- [Elasticsearch](https://github.com/elastic/elasticsearch)\n",
    "- [Anserini](https://github.com/castorini/anserini)\n",
    "- [Terrier](https://github.com/terrier-org/terrier-core)\n",
    "- [Whoosh](https://pypi.org/project/Whoosh/)\n",
    "\n",
    "As Python is becoming the standard programming language in Data Science and Deep Learning, Python interfaces have been added to several libraries:\n",
    "- [Elasticsearch-py](https://github.com/elastic/elasticsearch-py) for Elasticsearch\n",
    "- [Pyserini](https://github.com/castorini/pyserini/) for Anserini\n",
    "- [Py-Terrier](https://github.com/terrier-org/pyterrier) for Terrier\n",
    "- [BEIR](https://github.com/beir-cellar/beir.git) for BEIR\n",
    "\n",
    "The role of these Python interfaces is to understand your Python code and to map it onto the underlying service.\n",
    "For example, PyTerrier is a Python layer above Terrier:\n",
    "![PyTerrier](figures/PyTerrier.png \"PyTerrier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: PyTerrier\n",
    "\n",
    "In our first labs, we will be using PyTerrier: a new Python Framework that makes it easy to perform information retrieval experiments in Python while using the Java-based Terrier platform for the expensive indexing and retrieval operations.\n",
    "\n",
    "In particular, the material of the lab is heavily based on the [ECIR 2021 tutorial](https://github.com/terrier-org/ecir2021tutorial) with PyTerrier and [OpenNIR](https://github.com/Georgetown-IR-Lab/OpenNIR) search toolkits.\n",
    "\n",
    "Another useful resource is the [PyTerrier documentation](https://pyterrier.readthedocs.io/_/downloads/en/latest/pdf/).\n",
    "\n",
    "NB. You can choose any library you prefer to develop your final project. \n",
    "Our labs aim to provide guidance into applying the theoretical content of the lectures in practice.\n",
    "As such, we only use one library and a small dataset during the lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "PyTerrier does not yet easily install on Windows.\n",
    "\n",
    "If you do not have a Linux or macOS device, one of the easiest options is to use <a href=\"https://colab.research.google.com/\">Google Colab</a>.\n",
    "\n",
    "Get in touch with the TA if you need help setting up Google Colab!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Pre-requisites\n",
    "\n",
    "PyTerrier requires:\n",
    "- Python 3.6 or newer\n",
    "    + You can check your Python version by running `python --version` or `python3 --version` on the terminal\n",
    "    + You can download a newer version from [here](https://www.python.org/downloads/)\n",
    "    + Once you have a valid Python version installed, make sure your Jupyter notebook is using it (`Kernel -> Change Kernel`)\n",
    "- Java 11 or newer\n",
    "    + You can check your Java version by running `java --version` on the terminal\n",
    "    + You can download and install Java 11 from [JDK 11](https://www.oracle.com/java/technologies/javase-jdk11-downloads.html) or [OpenJDK 11](http://jdk.java.net/archive/). Several tutorials exist to help you in this task, such as [this one for Linux](https://computingforgeeks.com/how-to-install-java-11-on-ubuntu-debian-linux/) and [this one for macOS](https://mkyong.com/java/how-to-install-java-on-mac-osx/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Installation\n",
    "\n",
    "PyTerrier can be easily installed from the terminal using Pip:\n",
    "```bash\n",
    "pip install python-terrier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (0.8.1)\n",
      "Requirement already satisfied: sklearn in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.0)\n",
      "Requirement already satisfied: tqdm in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (4.64.0)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.5.1)\n",
      "Requirement already satisfied: requests in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (2.27.1)\n",
      "Requirement already satisfied: wget in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: scipy in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.8.0)\n",
      "Requirement already satisfied: chest in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: joblib in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.1.0)\n",
      "Requirement already satisfied: matchpy in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: dill in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.3.4)\n",
      "Requirement already satisfied: jinja2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (3.0.3)\n",
      "Requirement already satisfied: more-itertools in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (8.13.0)\n",
      "Requirement already satisfied: ir-measures>=0.2.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.3.0)\n",
      "Requirement already satisfied: statsmodels in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (0.13.2)\n",
      "Requirement already satisfied: numpy in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.22.3)\n",
      "Requirement already satisfied: pandas in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.4.2)\n",
      "Requirement already satisfied: deprecation in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (2.1.0)\n",
      "Requirement already satisfied: pyjnius~=1.3.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from python-terrier) (1.3.0)\n",
      "Requirement already satisfied: typish>=1.7.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.0.0)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.8)\n",
      "Collecting lxml>=4.5.2\n",
      "  Using cached lxml-4.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.1)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.11.1)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.3.2.post1)\n",
      "Requirement already satisfied: pyndeval>=0.0.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier) (0.0.2)\n",
      "Requirement already satisfied: pytrec-eval-terrier==0.5.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier) (0.5.2)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier) (1.0.10)\n",
      "Requirement already satisfied: six>=1.7.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: cython in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier) (0.29.28)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from requests->python-terrier) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from requests->python-terrier) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from requests->python-terrier) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from requests->python-terrier) (3.3)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: packaging in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from deprecation->python-terrier) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from jinja2->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from packaging->deprecation->python-terrier) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from pandas->python-terrier) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from pandas->python-terrier) (2022.1)\n",
      "Requirement already satisfied: scikit-learn in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from sklearn->python-terrier) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from scikit-learn->sklearn->python-terrier) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/tokereines/miniconda3/envs/nir/lib/python3.9/site-packages (from statsmodels->python-terrier) (0.5.2)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Configuration\n",
    "\n",
    "To use PyTerrier, we need to both import it and initialize it.\n",
    "The initialization with the `init()` method makes PyTerrier download Terrier's JAR file as well as start the Java virtual machine.\n",
    "To avoid `init()` being called more than once, we can check if it's being initialized through the `started()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Data\n",
    "\n",
    "In our labs, we will be using a subset of the small version of [WikIR](https://www.aclweb.org/anthology/2020.lrec-1.237.pdf) dataset for English.\n",
    "\n",
    "The data is located inside the `data/` folder, and consists of:\n",
    "- `lab_docs.csv`: CSV file of document number and document text\n",
    "- `lab_topics.csv`: CSV file of query id and query text\n",
    "- `lab_qrels.csv`: CSV file of annotations with schema `qid, docno, label, iteration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2453, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>935016</td>\n",
       "      <td>he emigrated to france with his family in 1956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2360440</td>\n",
       "      <td>after being ambushed by the germans in novembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347765</td>\n",
       "      <td>she was the second ship named for captain alex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969335</td>\n",
       "      <td>world war ii was a global war that was under w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1576938</td>\n",
       "      <td>the ship was ordered on 2 april 1942 laid down...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     docno                                               text\n",
       "0   935016  he emigrated to france with his family in 1956...\n",
       "1  2360440  after being ambushed by the germans in novembe...\n",
       "2   347765  she was the second ship named for captain alex...\n",
       "3  1969335  world war ii was a global war that was under w...\n",
       "4  1576938  the ship was ordered on 2 april 1942 laid down..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df = pd.read_csv('data/lab_docs.csv', dtype=str)\n",
    "print(docs_df.shape)\n",
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2674</td>\n",
       "      <td>computer animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340095</td>\n",
       "      <td>2020 summer olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1502917</td>\n",
       "      <td>train station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2574</td>\n",
       "      <td>chinese cuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                 query\n",
       "0  1015979    president of chile\n",
       "1     2674    computer animation\n",
       "2   340095  2020 summer olympics\n",
       "3  1502917         train station\n",
       "4     2574       chinese cuisine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.read_csv('data/lab_topics.csv', dtype=str)\n",
    "print(topics_df.shape)\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2454, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1015979</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015979</td>\n",
       "      <td>2226456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1514612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1119171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1053174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid    docno label iteration\n",
       "0  1015979  1015979     2         0\n",
       "1  1015979  2226456     1         0\n",
       "2  1015979  1514612     1         0\n",
       "3  1015979  1119171     1         0\n",
       "4  1015979  1053174     1         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df = pd.read_csv('data/lab_qrels.csv', dtype=str)\n",
    "print(qrels_df.shape)\n",
    "qrels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Indexing and Indexes\n",
    "\n",
    "To perform the task of retrieving relevant documents for a given query, a search engine needs to know which documents are available and index them to efficiently retrieve them.\n",
    "\n",
    "In PyTerrier, we can create an index from a Pandas DataFrame with the `DFIndexer` method.\n",
    "The index, with all its data structures, is written into a directory called `indexes/default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./indexes/default/data.properties'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = pt.DFIndexer(\"./indexes/default\", overwrite=True)\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index_ref.toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `IndexRef` is basically a string saying where an index is stored.\n",
    "A PyTerrier index contains several files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.8M\r\n",
      "-rw-r--r-- 1 tokereines tokereines 271K May 12 10:11 data.direct.bf\r\n",
      "-rw-r--r-- 1 tokereines tokereines  41K May 12 10:11 data.document.fsarrayfile\r\n",
      "-rw-r--r-- 1 tokereines tokereines 281K May 12 10:11 data.inverted.bf\r\n",
      "-rw-r--r-- 1 tokereines tokereines 2.0M May 12 10:11 data.lexicon.fsomapfile\r\n",
      "-rw-r--r-- 1 tokereines tokereines 1017 May 12 10:11 data.lexicon.fsomaphash\r\n",
      "-rw-r--r-- 1 tokereines tokereines  93K May 12 10:11 data.lexicon.fsomapid\r\n",
      "-rw-r--r-- 1 tokereines tokereines  63K May 12 10:11 data.meta-0.fsomapfile\r\n",
      "-rw-r--r-- 1 tokereines tokereines  20K May 12 10:11 data.meta.idx\r\n",
      "-rw-r--r-- 1 tokereines tokereines  55K May 12 10:11 data.meta.zdata\r\n",
      "-rw-r--r-- 1 tokereines tokereines 4.2K May 12 10:11 data.properties\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh indexes/default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files represent several data structures:\n",
    "- Lexicon: Records the list of all unique terms and their statistics\n",
    "- Document index: Records the statistics of all documents (e.g. document length)\n",
    "- Inverted index: Records the mapping between terms and documents\n",
    "- Meta index: Records document metadata (e.g. document number, URL, raw text, etc passed through `indexer.index()`)\n",
    "- Direct index: Records terms for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an `IndexRef`, we can load it to an actual index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jnius.reflect.org.terrier.structures.Index"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# lets see what type index is\n",
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this object refers to Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) type. \n",
    "\n",
    "Looking at the linked Javadoc, we can see that this Java object has methods such as:\n",
    " - `getCollectionStatistics()`\n",
    " - `getInvertedIndex()`\n",
    " - `getLexicon()`\n",
    "\n",
    "Let's see what is returned by the `CollectionStatistics()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.terrier.structures.bit.BitPostingIndex@3f56875e\n"
     ]
    }
   ],
   "source": [
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(index.getEnd())\n",
    "print(index.getStart())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.getDocumentIndex().getDocumentLength(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['935016']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.getMetaIndex().getAllItems(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon\n",
    "\n",
    "What is our vocabulary of terms?\n",
    "\n",
    "This is the [Lexicon](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html), which can be iterated easily from Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agenda -> term9700 Nt=3 TF=3 maxTF=1 @{0 30035 3}\n",
      "agent -> term17 Nt=40 TF=51 maxTF=3 @{0 30042 1}\n",
      "aggi -> term9651 Nt=1 TF=1 maxTF=1 @{0 30099 6}\n",
      "aggrav -> term18279 Nt=2 TF=2 maxTF=1 @{0 30102 2}\n",
      "aggreg -> term9189 Nt=3 TF=3 maxTF=1 @{0 30107 4}\n"
     ]
    }
   ],
   "source": [
    "ix_range = range(1900, 1905)\n",
    "for ix, kv in enumerate(index.getLexicon()):\n",
    "    if ix in ix_range:\n",
    "        print(f\"{kv.getKey()} -> {kv.getValue().toString()}\")\n",
    "    elif ix > ix_range[-1]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, iterating over the Lexicon returns a pair of String term and a [LexiconEntry](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object – which itself is an [EntryStatistics](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html) – and contains information including the statistics of that term:\n",
    "- `Nt` is the is the number of unique documents that each term occurs in (this is useful for calculating IDF)\n",
    "- `TF` is the total number of occurrences – some weighting models use this instead of Nt\n",
    "- The numbers in the `@{}` are pointers for Terrier to find that term in the inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "\n",
    "The inverted index tells us in which _documents_ each term occurs.\n",
    "\n",
    "The LexiconEntry is also the pointer to find the postings (i.e. occurrences) for that term in the inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID(520) TF(1) doclen=117\n",
      "ID(709) TF(1) doclen=112\n",
      "ID(1052) TF(1) doclen=107\n"
     ]
    }
   ],
   "source": [
    "pointer = index.getLexicon()[\"agenda\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(f\"{posting.toString()} doclen={posting.getDocumentLength()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can see that `\"agenda\"` occurs once in documents with ids 520, 709 and 1052.\n",
    "\n",
    "Note that these are internal document ids of Terrier.\n",
    "We can know which documents (i.e. the string \"docno\" in the corpus DataFrame) from the metaindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID(520) TF(1) doclen=117 docno=254370\n",
      "ID(709) TF(1) doclen=112 docno=626787\n",
      "ID(1052) TF(1) doclen=107 docno=305924\n"
     ]
    }
   ],
   "source": [
    "meta = index.getMetaIndex()\n",
    "pointer = index.getLexicon()[\"agenda\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    docno = meta.getItem(\"docno\", posting.getId())\n",
    "    print(f\"{posting.toString()} doclen={posting.getDocumentLength()} docno={docno}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing\n",
    "\n",
    "Looking at the terms in the Lexicon, do you think the index applied any text pre-processing?\n",
    "\n",
    "What happens if we lookup a very frequent term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'term9700 Nt=3 TF=3 maxTF=1 @{0 30035 3}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.getLexicon()[\"agenda\"].toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, Terrier removes standard stopwords and applies Porter's stemmer by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Variants\n",
    "\n",
    "We can modify the pre-processing transformations applied by Terrier when creating an index by changing its `term pipelines` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No pre-processing\n",
    "indexer.setProperty(\"tokeniser\", \"UTFTokeniser\") # Replaces the default EnglishTokeniser, which makes assumptions specific to English\n",
    "indexer.setProperty(\"termpipelines\", \"\") # Removes the default PorterStemmer (English)\n",
    "index_ref2 = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal\n",
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [org.terrier.terms](http://terrier.org/docs/current/javadoc/org/terrier/terms/package-summary.html) package for a list of the available term pipeline objects provided by Terrier.\n",
    "\n",
    "Similarly, tokenization is controlled by the _“tokeniser”_ property. For example:\n",
    "```python\n",
    "indexer.setProperty(\"tokeniser\", \"UTFTokeniser\")\n",
    "```\n",
    "\n",
    "[EnglishTokeniser](http://terrier.org/docs/current/javadoc/org/terrier/indexing/tokenisation/EnglishTokeniser.html) is the default tokeniser. Other tokenisers are listed in [org.terrier.indexing.tokenisation](http://terrier.org/docs/current/javadoc/org/terrier/indexing/tokenisation/package-summary.html) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also use the `blocks=True` argument for the index to store position information of every term in each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store position information\n",
    "# todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an Index\n",
    "\n",
    "Creating an index can take significant time for large document collections.\n",
    "We can load an index that we previously computed by specifying its path to `\"data/properties\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ref = pt.IndexRef.of(\"./indexes/default/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Searching an Index\n",
    "\n",
    "Now that we have an index, let's perform retrieval on it!\n",
    "\n",
    "In PyTerrier, search is done through the `BatchRetrieve()` method.\n",
    "BatchRetrieve takes two main arguments:\n",
    "- an index\n",
    "- a weighting model\n",
    "\n",
    "For instance, we can search for the word `\"wall\"` with our index and a term frequency (`Tf`) model by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "tf.search(\"wall\")  # NB. This can also be a multi-word expression (e.g. \"white wall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `search()` method returns a DataFrame with columns:\n",
    " - `qid`: This is equal to \"1\" here since we only have a single query\n",
    " - `docid`: This is Terrier's internal integer for each document\n",
    " - `docno`: This is the external (string) unique identifier for each document\n",
    " - `rank`: This shows the descending order by score of retrieved documents\n",
    " - `score`: Since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n",
    " - `query`: The input query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a DataFrame of one or more queries to the `transform()` method (rather than the `search()` method) with queries numbered \"q1\", \"q2\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.DataFrame([[\"q1\", \"dragon\"], [\"q2\", \"wall\"]], columns=[\"qid\", \"query\"])\n",
    "tf.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, since `transform()` is the default method of a BatchRetrieve object `br`, we can directly write `br(queries)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, while we have used the simple `\"Tf\"` ranking function in the example above, Terrier supports many other models that can be used by simply changing the `wmodel=\"Tf\"` argument of `BatchRetrieve` (e.g. `wmodel=\"BM25\"` for BM25 scoring).\n",
    "A list of supported models is available in the [documentation](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html).\n",
    "\n",
    "We can also tune internal Terrier configurations through the `properties` and `controls` arguments.\n",
    "For example, we can tune [BM25](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/BM25.html)'s $b$, $k_1$ and $k_3$ parameters (c.f. Equation 4 [here](http://ir.dcs.gla.ac.uk/smooth/he-ecir05.pdf)) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")  # default parameters\n",
    "bm25v2 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"c\": 0.1, \"bm25.k_1\": 2.0, \"bm25.k_3\": 10})\n",
    "bm25v3 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"c\": 8, \"bm25.k_1\": 1.4, \"bm25.k_3\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the $b$ parameters is set via the generic `\"c\"` control parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Measuring Retrieval Performance\n",
    "\n",
    "Ranking metrics allow us to decide which search engine models are better than others for our application.\n",
    "\n",
    "While we will look into evaluation metrics in a future lab, we can use PyTerrier's `Experiment` abstraction to evaluate multiple (BatchRetrieve) systems on queries \"Q\" and labels \"RA\":\n",
    "```python\n",
    "pt.Experiment([br1, br2], Q, RA, eval_metrics=[\"map\", \"ndcg\"])\n",
    "```\n",
    "\n",
    "For instance, we can evaluate the MAP and NDCG metrics of the models we defined so far on the first three topics of our collection as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = qrels_df.astype({'label': 'int32'})\n",
    "pt.Experiment(\n",
    "    retr_systems=[tf, bm25, bm25v2, bm25v3],\n",
    "    names=['TF', 'BM25', 'BM25 (0.1, 2.0, 10)', 'BM25 (8, 1.4, 10)'],\n",
    "    topics=topics_df[:3],\n",
    "    qrels=qrels_df,\n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}